{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import face_recognition\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ebi/machinelearning/end_to_end_ml_projects/ete_face_recognition/research'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ebi/machinelearning/end_to_end_ml_projects/ete_face_recognition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebi/machinelearning/end_to_end_ml_projects/ete_face_recognition/venv/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ebi/machinelearning/end_to_end_ml_projects/ete_face_recognition'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ebi/machinelearning/end_to_end_ml_projects/ete_face_recognition'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {}\n",
    "args['dataset'] = os.path.join(\"artifacts\", \"data_ingestion\", \"dataset\")\n",
    "args['encoding'] = os.path.join(\"artifacts\", \"trained_model\", \"encoding.pickle\")\n",
    "args['detection_method'] = 'cnn'\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create facial embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_facial_embeddings(args):\n",
    "    # grab the path to the input images in our dataset\n",
    "    print(\"[INFO] quantifing faces...\")\n",
    "    imagePaths = list(paths.list_images(args['dataset']))\n",
    "    # initialize the list of known encoding and known names\n",
    "    KnownEncodings = []\n",
    "    KnownNames = []\n",
    "    for (i, imagePath) in enumerate(imagePaths):\n",
    "        print(i, imagePath)\n",
    "    # dlib and gace_recognition are in RGB color channel order\n",
    "    print('[INFO] processing image...')\n",
    "    ti = time.time()\n",
    "    # loop over the image paths\n",
    "    for (i, imagePath) in enumerate(imagePaths):\n",
    "        #extract the person name from the image path\n",
    "        print('{}/{}'.format(i+1, len(imagePaths)), end=', ')\n",
    "        name = imagePath.split(os.path.sep)[-2]\n",
    "        # load the input image and convert it to RGB\n",
    "        image = cv2.imread(imagePath)\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #detect the (x, y)-coordinates of the bounding boxes corresponding\n",
    "        # to each face in the image\n",
    "        boxes = face_recognition.face_locations(rgb, model=args['detection_method'])\n",
    "        #compute the facial embedding for the face, ie, to turn the\n",
    "        # bounding boxes of the face into a list of 128 numbers\n",
    "        encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "        #loop over the encodings\n",
    "        for encoding in encodings:\n",
    "            #add each encoding + name to our set of known names and encodings\n",
    "            KnownEncodings.append(encoding)\n",
    "            KnownNames.append(name)\n",
    "    print('Done!')\n",
    "    print('Time taken: {:.1f} minutes'.format((time.time() - ti)/60))\n",
    "    #dump the names and encodings to disk for future recall\n",
    "    #encoding.pickle contains the 128-d face embeddings for each \n",
    "    # face in our dataset\n",
    "    print('[INFO] serializing encodings...')\n",
    "    data = {'encoding': KnownEncodings, 'names':KnownNames}\n",
    "    f = open(args['encoding'], 'wb')\n",
    "    f.write(pickle.dumps(data))\n",
    "    f.close()\n",
    "    print('Done!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] quantifing faces...\n",
      "0 artifacts/data_ingestion/dataset/john_hammond/John Hammond (2).jpg\n",
      "1 artifacts/data_ingestion/dataset/john_hammond/John Hammond (3).jpg\n",
      "2 artifacts/data_ingestion/dataset/john_hammond/John Hammond (5).jpg\n",
      "3 artifacts/data_ingestion/dataset/john_hammond/John Hammond (4).jpg\n",
      "4 artifacts/data_ingestion/dataset/john_hammond/John Hammond (1).jpg\n",
      "5 artifacts/data_ingestion/dataset/owen_grady/Owen Grady (3).jpg\n",
      "6 artifacts/data_ingestion/dataset/owen_grady/Owen Grady (1).jpg\n",
      "7 artifacts/data_ingestion/dataset/owen_grady/Owen Grady (5).jpg\n",
      "8 artifacts/data_ingestion/dataset/owen_grady/Owen Grady (4).jpg\n",
      "9 artifacts/data_ingestion/dataset/owen_grady/Owen Grady (2).jpg\n",
      "10 artifacts/data_ingestion/dataset/ian_malcolm/Ian_Malcolm_(Jeff_Goldblum).jpg\n",
      "11 artifacts/data_ingestion/dataset/ian_malcolm/Ian Malcolm (2).jpg\n",
      "12 artifacts/data_ingestion/dataset/ian_malcolm/Ian Malcolm (4).jpg\n",
      "13 artifacts/data_ingestion/dataset/ian_malcolm/Ian Malcolm (1).jpg\n",
      "14 artifacts/data_ingestion/dataset/ian_malcolm/Ian Malcolm (3).jpg\n",
      "15 artifacts/data_ingestion/dataset/alan_grant/Alan Grant (3).jpg\n",
      "16 artifacts/data_ingestion/dataset/alan_grant/Alan Grant (1).jpg\n",
      "17 artifacts/data_ingestion/dataset/alan_grant/Alan Grant (4).jpg\n",
      "18 artifacts/data_ingestion/dataset/alan_grant/Alan Grant (2).jpg\n",
      "19 artifacts/data_ingestion/dataset/alan_grant/Jurassic-World-Dominion-trailer-Sam-Neill-returns-as-Dr-Alan-Grant.jpg\n",
      "20 artifacts/data_ingestion/dataset/ellie_sattler/Ellie Sattler (4).jpg\n",
      "21 artifacts/data_ingestion/dataset/ellie_sattler/Ellie Sattler (1).jpg\n",
      "22 artifacts/data_ingestion/dataset/ellie_sattler/Ellie Sattler (3).jpg\n",
      "23 artifacts/data_ingestion/dataset/ellie_sattler/Ellie Sattler (2).jpg\n",
      "24 artifacts/data_ingestion/dataset/ellie_sattler/Ellie Sattler (5).jpg\n",
      "25 artifacts/data_ingestion/dataset/claire_dearing/Claire Dearing (2).jpg\n",
      "26 artifacts/data_ingestion/dataset/claire_dearing/Claire Dearing (1).jpg\n",
      "27 artifacts/data_ingestion/dataset/claire_dearing/Claire Dearing (3).jpg\n",
      "28 artifacts/data_ingestion/dataset/claire_dearing/Claire Dearing (4).jpg\n",
      "29 artifacts/data_ingestion/dataset/claire_dearing/Claire Dearing (5).jpg\n",
      "[INFO] processing image...\n",
      "1/30, 2/30, 3/30, 4/30, 5/30, 6/30, 7/30, 8/30, 9/30, 10/30, 11/30, 12/30, 13/30, 14/30, 15/30, 16/30, 17/30, 18/30, 19/30, 20/30, 21/30, 22/30, 23/30, 24/30, 25/30, 26/30, 27/30, 28/30, 29/30, 30/30, Done!\n",
      "Time taken: 1.7 minutes\n",
      "[INFO] serializing encodings...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "create_facial_embeddings(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognize faces in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts/data_ingestion/dataset/alan_grant/Alan Grant (2).jpg\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "args['image'] = os.path.join(\"artifacts\",\"data_ingestion\",\"dataset\",   'alan_grant', \"Alan Grant (2).jpg\")\n",
    "print(args['image'])\n",
    "args['detection_method2'] = 'hog'\n",
    "args['output'] = os.path.join(\"artifacts\", \"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognise_faces(args):\n",
    "    ti = time.time()\n",
    "    #load the known faces and embeddings\n",
    "    print('[INFO] loading encodings...')\n",
    "    data = pickle.loads(open(args['encoding'], 'rb').read())\n",
    "    #load the input image and convert it from BGR to RGB\n",
    "    image = cv2.imread(args['image'])\n",
    "    print(image.shape)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    #detect the (x, y)-coordinates of the bounding boxes \n",
    "    print('[INFO] recognising faces...')\n",
    "    boxes = face_recognition.face_locations(rgb, model=args['detection_method2'])\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "    #initialize the list of names for each face detected\n",
    "    names = []\n",
    "    \n",
    "    #loop over the facial embeddings\n",
    "    for encoding in encodings:\n",
    "        #attempt to match each face in the input image to\n",
    "        # our known encodings, function returns a list of\n",
    "        # True/False values, one for each known encoding\n",
    "        #Internally, the compare_faces function is computing\n",
    "        # the Euclidean distance between the candidate embedding\n",
    "        # and all faces in our known encodings\n",
    "        votes = face_recognition.compare_faces(data['encoding'], encoding)\n",
    "        #check to see if a match is found\n",
    "        if True in votes:\n",
    "            #find the corresponding names of all faces matched(vote = True)\n",
    "            matches = [name for name, vote in list(zip(data['names'], votes)) if vote == True]\n",
    "            #determine the most frequently occuring name\n",
    "            name = Counter(matches).most_common()[0][0]\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        #update the list of names\n",
    "        names.append(name)\n",
    "    print([' '.join([e.title() for e in name.split('_')]) for name in names])\n",
    "    print('Time taken: {:.1f} seconds'.format(time.time() - ti))\n",
    "    \n",
    "    #visualise with bounding boxes and labeled names, loop over the recognised faces\n",
    "    for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "        #draw the predicted face name on the image\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        y = top - 15 if top - 15 > 15 else top + 15\n",
    "        cv2.putText(image, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "        \n",
    "    #display the resulting frame, press 'q' to exit\n",
    "    window_text = args['image'].split(os.path.sep)[-1]\n",
    "    cv2.imshow(window_text, image)\n",
    "    while True:\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    #save output image\n",
    "    cv2.imwrite(args['output'] + '_output.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading encodings...\n",
      "(464, 610, 3)\n",
      "[INFO] recognising faces...\n",
      "['Alan Grant']\n",
      "Time taken: 0.2 seconds\n"
     ]
    }
   ],
   "source": [
    "recognise_faces(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
